{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training with PyTorch\n",
    "\n",
    "Train a model that predicts whether or not a a file transfer is an anomaly (suspicious) or benign, based on its features (attributes). \n",
    "\n",
    "### 1. Import the required libraries and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the data into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/mftinput4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into two data frames: features (`X`) and target variable (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the data into training and test data sets. \n",
    "\n",
    "The `train_test_split` method of Scikit-learn can split the data set into random train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 614\n",
      "Number of samples in test set: 154\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(f\"Number of samples in training set: {X_train.shape[0]}\")\n",
    "print(f\"Number of samples in test set: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the data as PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train.values)\n",
    "X_test = torch.FloatTensor(X_test.values)\n",
    "y_train = torch.LongTensor(y_train.values)\n",
    "y_test = torch.LongTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the training features tensor and its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.0000e+00, 1.5000e+02, 7.8000e+01,  ..., 3.5200e+01, 6.9200e-01,\n",
       "         5.4000e+01],\n",
       "        [4.0000e+00, 9.7000e+01, 6.0000e+01,  ..., 2.8200e+01, 4.4300e-01,\n",
       "         2.2000e+01],\n",
       "        [0.0000e+00, 1.6500e+02, 9.0000e+01,  ..., 5.2300e+01, 4.2700e-01,\n",
       "         2.3000e+01],\n",
       "        ...,\n",
       "        [4.0000e+00, 9.4000e+01, 6.5000e+01,  ..., 2.4700e+01, 1.4800e-01,\n",
       "         2.1000e+01],\n",
       "        [1.1000e+01, 8.5000e+01, 7.4000e+01,  ..., 3.0100e+01, 3.0000e-01,\n",
       "         3.5000e+01],\n",
       "        [5.0000e+00, 1.3600e+02, 8.2000e+01,  ..., 0.0000e+00, 6.4000e-01,\n",
       "         6.9000e+01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([614, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the training target value tensor and its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([614])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Create and train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a simple neural network model with PyTorch.\n",
    "The network must take eight input features and output two target values, corresponding to the two possible outcomes, diabetes or no diabetes.\n",
    "The network also defines two internal layers, with 20 and 10 neurons respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed for reproducible results\n",
    "torch.manual_seed(20)\n",
    "\n",
    "\n",
    "class ANN_model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_input_features=8,\n",
    "        num_neurons_layer1=20,\n",
    "        num_neurons_layer2=10,\n",
    "        num_targets=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Define the neural network layers\n",
    "        self.layer1 = nn.Linear(num_input_features, num_neurons_layer1)\n",
    "        self.layer2 = nn.Linear(num_neurons_layer1, num_neurons_layer2)\n",
    "        self.out = nn.Linear(num_neurons_layer2, num_targets)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # pass the data through the layers\n",
    "        x = F.relu(self.layer1(X))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model and define the loss function, the optimizer, and the training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ANN_model()\n",
    "\n",
    "# == Backward Propagation Configuration ==\n",
    "# CrossEntropyLoss is a common loss function for classifcation\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# Use the Adam optimizer with a learning rate of 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0. Loss: 7.187566757202148\n",
      "Epoch: 10. Loss: 0.8532983064651489\n",
      "Epoch: 20. Loss: 0.7162446975708008\n",
      "Epoch: 30. Loss: 0.6571372747421265\n",
      "Epoch: 40. Loss: 0.6171259880065918\n",
      "Epoch: 50. Loss: 0.6081922054290771\n",
      "Epoch: 60. Loss: 0.6015171408653259\n",
      "Epoch: 70. Loss: 0.5953478813171387\n",
      "Epoch: 80. Loss: 0.5914437770843506\n",
      "Epoch: 90. Loss: 0.5878034830093384\n",
      "Epoch: 100. Loss: 0.5838866829872131\n",
      "Epoch: 110. Loss: 0.5791388154029846\n",
      "Epoch: 120. Loss: 0.5727564692497253\n",
      "Epoch: 130. Loss: 0.566633403301239\n",
      "Epoch: 140. Loss: 0.5580756068229675\n",
      "Epoch: 150. Loss: 0.5513748526573181\n",
      "Epoch: 160. Loss: 0.5447183847427368\n",
      "Epoch: 170. Loss: 0.5398930311203003\n",
      "Epoch: 180. Loss: 0.5355620980262756\n",
      "Epoch: 190. Loss: 0.5293850898742676\n",
      "Epoch: 200. Loss: 0.5238162279129028\n",
      "Epoch: 210. Loss: 0.5191245675086975\n",
      "Epoch: 220. Loss: 0.5141338109970093\n",
      "Epoch: 230. Loss: 0.5091280341148376\n",
      "Epoch: 240. Loss: 0.5019227862358093\n",
      "Epoch: 250. Loss: 0.5006561875343323\n",
      "Epoch: 260. Loss: 0.49190211296081543\n",
      "Epoch: 270. Loss: 0.4884668290615082\n",
      "Epoch: 280. Loss: 0.48289772868156433\n",
      "Epoch: 290. Loss: 0.4776309132575989\n",
      "Epoch: 300. Loss: 0.4728235900402069\n",
      "Epoch: 310. Loss: 0.4694846570491791\n",
      "Epoch: 320. Loss: 0.4665796160697937\n",
      "Epoch: 330. Loss: 0.46341150999069214\n",
      "Epoch: 340. Loss: 0.4596749544143677\n",
      "Epoch: 350. Loss: 0.451712042093277\n",
      "Epoch: 360. Loss: 0.44773247838020325\n",
      "Epoch: 370. Loss: 0.4446830749511719\n",
      "Epoch: 380. Loss: 0.4416937232017517\n",
      "Epoch: 390. Loss: 0.44779297709465027\n",
      "Epoch: 400. Loss: 0.4421921968460083\n",
      "Epoch: 410. Loss: 0.4325019121170044\n",
      "Epoch: 420. Loss: 0.42934802174568176\n",
      "Epoch: 430. Loss: 0.43760985136032104\n",
      "Epoch: 440. Loss: 0.43087247014045715\n",
      "Epoch: 450. Loss: 0.4260079562664032\n",
      "Epoch: 460. Loss: 0.4251379072666168\n",
      "Epoch: 470. Loss: 0.4202670753002167\n",
      "Epoch: 480. Loss: 0.4245058298110962\n",
      "Epoch: 490. Loss: 0.43060368299484253\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    y_pred = model.forward(X_train)\n",
    "    loss = loss_function(y_pred, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Epoch: {i}. Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate the model metrics.\n",
    "\n",
    "After the model is trained, evaluate the model against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       107\n",
      "           1       0.65      0.64      0.65        47\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.75      0.74      0.75       154\n",
      "weighted avg       0.78      0.79      0.79       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the predictions (y_predictions) given the test data\n",
    "y_predicted = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        predictions = model(data)\n",
    "        y_predicted.append(predictions.argmax())\n",
    "\n",
    "# Compare the predicted values for the test set (y_predicted)\n",
    "# against the expected values (y_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model has an accuracy value of 79%.\n",
    "\n",
    "You can improve the score by retraining the model after more sophisticated data engineering or by tweaking the model's hyper parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test the model with sample cases.\n",
    "Test the model with data from two patients: one patient with diabetes and one patient without diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tuple for textual display of prediction\n",
    "classes = ('No diabetes', 'Diabetes')\n",
    "\n",
    "\n",
    "def predict(patients: List[Dict]):\n",
    "    inputs_dataframe = pd.DataFrame(patients)\n",
    "    inputs_tensor = torch.FloatTensor(inputs_dataframe.values)\n",
    "    predictions = []\n",
    "    for case in inputs_tensor:\n",
    "        predictions_tensor = model(case)\n",
    "        prediction_index = predictions_tensor.argmax().item()\n",
    "        predictions.append(classes[prediction_index])\n",
    "    return predictions\n",
    "\n",
    "\n",
    "anomaly_filetransfer = {\n",
    "    \"Entropy\": 6.0,\n",
    "    \"FileAge\": 110.0,\n",
    "    \"CompressionRatio\": 65.0,\n",
    "    \"FileSize\": 15.0,\n",
    "    \"TransfeTime\": 1.0,\n",
    "    \"PacketSize\": 45.7,\n",
    "    \"TransferRate\": 0.627,\n",
    "    \"Age\": 50\n",
    "}\n",
    "\n",
    "no_anomaly_filetransfer = {\n",
    "    \"Entropy\": 0,\n",
    "    \"FileAge\": 88.0,\n",
    "    \"CompressionRatio\": 60.0, \n",
    "    \"FileSize\": 35.0,\n",
    "    \"TransferTime\": 1.0,\n",
    "    \"PacketSize\": 45.7,\n",
    "    \"TransferRate\": 0.27,\n",
    "    \"Age\": 20\n",
    "}\n",
    "\n",
    "predictions = predict([anpmaly_filetransfer, no_anomaly_filetransfer])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
